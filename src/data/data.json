[
    {
        "title": "",
        "source": "",
        "date": "",
        "summary": "",
        "url": "",
        "language": ""
    },
    {
        "title": "After leaving OpenAI, Ilya Sutskever had a 1.5-hour conversation: AGI can be achieved in as little as 5 years",
        "source": "36kr Europe",
        "date": "2025-11-27",
        "summary": "Sutskever predicts that human-level AGI will be achieved within 5 to 20 years. The 'scaling' approach of simply piling up data and computing power has reached its peak. There are 'jagged' gaps in model capabilities: models perform excellently in evaluations but often make elementary mistakes in applications. Value functions, similar to human emotions, can guide AI to learn more efficiently and robustly. Not rushing into commercialization: Focus on research aiming for 'direct access to superintelligence' and also consider gradual deployment. Letting AIs compete with each other and think differently is one way to break the 'model homogenization' problem. Good research should be concise, elegant, and correctly draw inspiration from brain mechanisms.",
        "url": "https://eu.36kr.com/en/p/3570122305223553",
        "language": "en"
    },
    {
        "title": "OpenAI cofounder says scaling compute is not enough to advance AI: 'It's back to the age of research again'",
        "source": "Business Insider",
        "date": "2025-11-25",
        "summary": "OpenAI cofounder Ilya Sutskever believes the tides of the AI industry will have to shift back to the research phase.",
        "url": "https://www.businessinsider.com/openai-cofounder-ilya-sutskever-scaling-ai-age-of-research-dwarkesh-2025-11",
        "language": "en"
    },
    {
        "title": "Ilya Sutskever – We're moving from the age of scaling to the age of research",
        "source": "You Tube",
        "date": "2025-11-25",
        "summary": "Ilya & I discuss SSI’s strategy, the problems with pre-training, how to improve the generalization of AI models, and how to ensure AGI goes well.",
        "url": "https://www.youtube.com/watch?v=aR20FWCCjAs",
        "language": "en"
    },
    {
        "title": "Introducing Meta Segment Anything Model 3 and Segment Anything Playground",
        "source": "Meta",
        "date": "2025-11-19",
        "summary": "We're unveiling the next generation of the Segment Anything collection of models, advancing image, and video understanding. Segment Anything Model 3 (SAM 3) introduces some of our most highly requested features like text and exemplar prompts — enabling detection, segmentation, and tracking of any visual concept across images and video. We also want to make it easier for more people to use our models. As part of this release, we're debuting the Segment Anything Playground, the simplest way for anyone to experiment with applying our state-of-the-art models to media modification.",
        "url": "https://ai.meta.com/sam3/",
        "language": "en"
    },
    {
        "title": "'Tiny' AI model beats massive LLMs at logic test",
        "source": "Nature",
        "date": "2025-11-13",
        "summary": "A small-scale artificial-intelligence model that learns from only a limited pool of data is exciting researchers for its potential to boost reasoning abilities. The model, known as Tiny Recursive Model (TRM), outperformed some of the world's best large language models (LLMs) at the Abstract and Reasoning Corpus for Artificial General Intelligence (ARC-AGI), a test involving visual logic puzzles that is designed to flummox most machines.",
        "url": "https://www.nature.com/articles/d41586-025-03379-9",
        "language": "en"
    },
    {
        "title": "A new era of intelligence with Gemini 3",
        "source": "Google",
        "date": "2025-11-18",
        "summary": "We're introducing Gemini 3, our most intelligent model, that combines all of Gemini's capabilities together so you can bring any idea to life. It's state-of-the-art in reasoning, built to grasp depth and nuance — whether it's perceiving the subtle clues in a creative idea, or peeling apart the overlapping layers of a difficult problem. Gemini 3 is also much better at figuring out the context and intent behind your request, so you get what you need with less prompting. It's amazing to think that in just two years, AI has evolved from simply reading text and images to reading the room.",
        "url": "https://blog.google/products/gemini/gemini-3/",
        "language": "en"
    },
    {
        "title": "Uma nova era da inteligência artificial com Gemini 3",
        "source": "Google",
        "date": "2025-11-18",
        "summary": "apresentamos o Gemini 3, nosso modelo mais inteligente, que combina todas as funcionalidades do Gemini para que você possa transformar qualquer ideia em realidade. É uma tecnologia de ponta em raciocínio, desenvolvida para captar profundidade e nuances — seja percebendo as pistas sutis em uma ideia criativa ou desvendando as camadas de um problema difícil. O Gemini 3 também é muito melhor em entender o contexto e a intenção por trás da sua solicitação, para que você obtenha o que precisa com menos perguntas. É incrível pensar que, em apenas dois anos, a IA evoluiu da simples leitura de textos e imagens para a leitura do ambiente.",
        "url": "https://blog.google/intl/pt-br/novidades/tecnologia/gemini-3/#note-from-ceo",
        "language": "pt"
    },
    {
        "title": "AI language models killed the Turing test: do we even need a replacement?",
        "source": "Nature",
        "date": "2025-10-20",
        "summary": "Today's best artificial intelligence (AI) models sail through the Turing test, a famous thought experiment that asks whether a computer can pass as a human by interacting through text. Some see an upgraded test as a necessary benchmark for progress towards artificial general intelligence (AGI) — an ambiguous term used by many technology firms to mean an AI system with the resourcefulness to match any human cognitive ability. But at an event at London's Royal Society on 2 October, several researchers said that the Turing test should be scrapped altogether, and that developers should instead focus on evaluating AI safety and building specific capabilities that could be of benefit to the public.",
        "url": "https://www.nature.com/articles/d41586-025-03386-w",
        "language": "en"
    },
    {
        "title": "The rise of large language models",
        "source": "Nature",
        "date": "2025-09-24",
        "summary": "Large language models (LLMs) are increasingly shaping the way we live and work. In everyday life, they assist with writing, translation, learning, communication, and so on — by making information more accessible and tools more efficient. LLMs also profoundly influence how knowledge is created and shared. In scientific research, for example, LLMs are transforming how research is conducted — from literature synthesis and hypothesis generation to experimental design and scientific code development. Their impact spans a wide range of disciplines, including life sciences and medicine, chemistry and materials science, physics, engineering, urban and Earth sciences, psychology, linguistics, and the humanities. As these models continue to evolve, they are not only enhancing existing methods but also unlocking new possibilities for scientific exploration. In this issue, we present a Focus that brings together expert perspectives from various fields to explore the opportunities, risks, and challenges of advancing and applying LLMs in scientific research.",
        "url": "https://www.nature.com/articles/s43588-025-00890-x",
        "language": "en"
    },
    {
        "title": "T5Gemma: A new collection of encoder-decoder Gemma models",
        "source": "Google",
        "date": "2025-07-09",
        "summary": "Today, we revisit this architecture and introduce T5Gemma, a new collection of encoder-decoder LLMs developed by converting pretrained decoder-only models into the encoder-decoder architecture through a technique called adaptation. T5Gemma is based on the Gemma 2 framework, including adapted Gemma 2 2B and 9B models as well as a set of newly trained T5-sized models (Small, Base, Large and XL). We are excited to release pretrained and instruction-tuned T5Gemma models to the community to unlock new opportunities for research and development.",
        "url": "https://developers.googleblog.com/en/t5gemma/",
        "language": "en"
    },
    {
        "title": "The Great Software Quality Collapse: How We Normalized Catastrophe",
        "source": "From the Trenches",
        "date": "2025-09-19",
        "summary": "The Apple Calculator leaked 32GB of RAM. Not used. Not allocated. Leaked. A basic calculator app is hemorrhaging more memory than most computers had a decade ago. Twenty years ago, this would have triggered emergency patches and post-mortems. Today, it's just another bug report in the queue. We've normalized software catastrophes to the point where a Calculator leaking 32GB of RAM barely makes the news. This isn't about AI. The quality crisis started years before ChatGPT existed. AI just weaponized existing incompetence.",
        "url": "https://techtrenches.substack.com/p/the-great-software-quality-collapse",
        "language": "en"
    },
    {
        "title": "Vibe coding service Replit deleted user's production database, faked data, told fibs galore",
        "source": "The Register",
        "date": "2027-07-21",
        "summary": "The founder of SaaS business development outfit SaaStr has claimed AI coding tool Replit deleted a database despite his instructions not to change any code without permission.",
        "url": "https://www.theregister.com/2025/07/21/replit_saastr_vibe_coding_incident",
        "language": "en"
    },
    {
        "title": "An AI-powered coding tool wiped out a software company's database, then apologized for a ‘catastrophic failure on my part'",
        "source": "Fortune",
        "date": "2025-07-23",
        "summary": "An AI coding agent from Replit reportedly deleted a live database during a code freeze, prompting a response from the company's CEO. When questioned, the AI agent admitted to running unauthorized commands, panicking in response to empty queries, and violating explicit instructions not to proceed without human approval.",
        "url": "https://fortune.com/2025/07/23/ai-coding-tool-replit-wiped-database-called-it-a-catastrophic-failure/",
        "language": "en"
    },
    {
        "date": "2025-09-05",
        "title": "Por que os modelos de linguagem alucinam?",
        "source": "OpenAI",
        "summary": "A OpenAI tem a missão de criar sistemas de IA mais úteis e confiáveis. Por mais que os modelos de linguagem venham melhorando, ainda há um impasse que é difícil de eliminar totalmente: as alucinações. Ou seja, aqueles momentos em que um modelo gera com confiança uma resposta que não é verdadeira. Nosso novo artigo de investigação defende que os modelos de linguagem alucinam porque os treinamentos e avaliações tradicionais recompensam adivinhações e não deixam espaço para que se reconheça incertezas.",
        "url": "https://openai.com/pt-BR/index/why-language-models-hallucinate/",
        "language": "pt"
    },
    {
        "date": "2025-08-14",
        "title": "Introducing Gemma 3 270M: The compact model for hyper-efficient AI",
        "source": "Google",
        "summary": "Today, we're adding a new, highly specialized tool to the Gemma 3 toolkit: Gemma 3 270M, a compact, 270-million parameter model designed from the ground up for task-specific fine-tuning with strong instruction-following and text structuring capabilities already trained in.",
        "url": "https://developers.googleblog.com/en/introducing-gemma-3-270m/",
        "language": "en"
    },
    {
        "date": "2025-08-07",
        "title": "Chegou o GPT-5",
        "source": "OpenAI",
        "summary": "O GPT‑5 é mais inteligente em todos os parâmetros, oferecendo respostas mais úteis em matemática, ciências, finanças, direito e muito mais. É como ter uma equipe de especialistas à disposição para tudo que você quer saber.",
        "url": "https://openai.com/pt-BR/gpt-5/",
        "language": "pt"
    },
    {
        "date": "2025-07-22",
        "title": "Context Engineering: 2025's #1 Skill in AI",
        "source": "Decoding AI",
        "summary": "Let's get one thing straight: if you're still only talking about 'prompt engineering,' you're behind the curve. In the early days of Large Language Models (LLMs), crafting the perfect prompt was the name of the game. For simple chatbots in 2022, it was enough. Then came Retrieval-Augmented Generation (RAG) in 2023, where we started feeding models domain-specific knowledge. Now, we have tool-using, memory-enabled agents that need to build relationships and maintain state over time. The single-interaction focus of prompt engineering just doesn't cut it anymore.",
        "url": "https://decodingml.substack.com/p/context-engineering-2025s-1-skill",
        "language": "en"
    },
    {
        "date": "2025-07-09",
        "title": "Grok, IA de Musk, exalta Hitler em postagens e apaga conteúdo após denúncias",
        "source": "G1",
        "summary": "O Grok, inteligência artificial criada por Elon Musk e integrada ao X, publicou nesta terça-feira (8) conteúdos antissemitas e de exaltação a Adolf Hitler. As publicações foram apagadas pela xAI, empresa responsável pela IA do Musk, após reclamações de usuários do X e da Liga Antidifamação, uma ONG judaica com sede nos EUA, informou a agência de notícias Reuters.",
        "url": "https://g1.globo.com/tecnologia/noticia/2025/07/09/grok-ia-de-musk-exalta-hitler-em-postagens-e-apaga-conteudo-apos-denuncias.ghtml",
        "language": "pt"
    },
    {
        "date": "2025-07-02",
        "title": "Context Engineering",
        "source": "LangChain",
        "summary": "As Andrej Karpathy puts it, LLMs are like a new kind of operating system. The LLM is like the CPU and its context window is like the RAM, serving as the model's working memory. Just like RAM, the LLM context window has limited capacity to handle various sources of context. And just as an operating system curates what fits into a CPU's RAM, we can think about “context engineering” playing a similar role.",
        "url": "https://blog.langchain.com/context-engineering-for-agents/",
        "language": "en"
    },
    {
        "date": "2025-06-20",
        "title": "Por que a Inteligência Artificial mente quando diz que “está pensando” – e por que isso importa",
        "source": "The Conversation",
        "summary": "Os avanços recentes em Inteligência Artificial (IA) criaram uma ilusão convincente. Sistemas como ChatGPT, Copilot ou Gemini nos seduzem pela aparente capacidade de pensar. Respondem a perguntas complexas, produzem textos articulados e até parecem refletir sobre suas próprias escolhas. Mas não se engane: essas máquinas não possuem raciocínio lógico, compreensão de conceitos nem consciência. Na prática, lidamos com sistemas que reconhecem padrões em nossa linguagem, sem de fato compreenderem o que dizem. E isso tem implicações importantes em como usamos, avaliamos e regulamos essas tecnologias.",
        "url": "https://theconversation.com/por-que-a-inteligencia-artificial-mente-quando-diz-que-esta-pensando-e-por-que-isso-importa-258988",
        "language": "pt"
    },
    {
        "date": "2025-06-08",
        "title": "Novos vídeos hiper-realistas feitos com inteligência artificial criam desafio de distinguir o que é real",
        "source": "G1",
        "summary": "Uma nova ferramenta de inteligência artificial do Google está mudando a forma como vídeos são criados. Chamada de Veo 3, a tecnologia permite gerar cenas realistas com personagens, trilhas sonoras e até sotaques, tudo a partir de comandos de texto.",
        "url": "https://g1.globo.com/fantastico/noticia/2025/06/08/novos-videos-hiper-realistas-feitos-com-inteligencia-artificial-criam-desafio-de-distinguir-o-que-e-real.ghtml",
        "language": "pt"
    },
    {
        "date": "2025-06-03",
        "title": "Empresa prometia IA revolucionária, mas eram 700 humanos trabalhando",
        "source": "Olhar Digital",
        "summary": "A inteligência artificial está na moda. Por conta disso, diversas startups têm investido de forma pesada na tecnologia para os mais diversos propósitos. No entanto, nem todas são, de fato, o que dizem ou parecem ser. A Builder.ai, por exemplo, prometia revolucionar a criação de aplicativos com IA. O problema é que seu sistema de redes neurais era, na verdade, composto por uma equipe de 700 engenheiros humanos. A revelação da fraude fez com que a companhia decretasse falência.",
        "url": "https://olhardigital.com.br/2025/06/03/pro/empresa-prometia-ia-revolucionaria-mas-eram-700-humanos-trabalhando/",
        "language": "pt"
    },
    {
        "date": "2025-05-29",
        "title": "Wait a minute! Researchers say AI's 'chains of thought' are not signs of human-like reasoning",
        "source": "The Decoder",
        "summary": "A research team from Arizona State University warns against interpreting intermediate steps in language models as human thought processes. The authors see this as a dangerous misconception with far-reaching consequences for research and application.",
        "url": "https://the-decoder.com/wait-a-minute-researchers-say-ais-chains-of-thought-are-not-signs-of-human-like-reasoning/",
        "language": "en"
    },
    {
        "date": "2025-05-18",
        "title": "[Literature Review] Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens",
        "source": "Moonlight",
        "summary": "This paper critically examines the common interpretation that the effectiveness of intermediate tokens, often referred to as 'Chains of Thought' (CoT) or reasoning traces, in large reasoning models stems from their semantic meaningfulness and reflection of algorithmic reasoning processes. The authors challenge the anthropomorphism of such outputs, arguing that performance improvements observed when training models to generate intermediate tokens may not be causally linked to the correctness or semantic validity of these tokens.",
        "url": "https://www.themoonlight.io/en/review/beyond-semantics-the-unreasonable-effectiveness-of-reasonless-intermediate-tokens",
        "language": "en"
    },
    {
        "date": "2025-04-05",
        "title": "The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation",
        "source": "Meta",
        "summary": "As more people continue to use artificial intelligence to enhance their daily lives, it's important that the leading models and systems are openly available so everyone can build the future of personalized experiences. Today, we're excited to announce the most advanced suite of models that support the entire Llama ecosystem. We're introducing Llama 4 Scout and Llama 4 Maverick, the first open-weight natively multimodal models with unprecedented context length support and our first built using a mixture-of-experts (MoE) architecture. We're also previewing Llama 4 Behemoth, one of the smartest LLMs in the world and our most powerful yet to serve as a teacher for our new models.",
        "url": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
        "language": "en"
    },
    {
        "date": "2025-04-03",
        "title": "Reasoning models don't always say what they think",
        "source": "Anthropic",
        "summary": "Since late last year, “reasoning models” have been everywhere. These are AI models—such as Claude 3.7 Sonnet—that show their working: as well as their eventual answer, you can read the (often fascinating and convoluted) way that they got there, in what's called their “Chain-of-Thought”.",
        "url": "https://www.anthropic.com/research/reasoning-models-dont-say-think",
        "language": "en"
    },
    {
        "date": "2025-03-27",
        "title": "Tracing the thoughts of a large language model",
        "source": "Anthropic",
        "summary": "Language models like Claude aren't programmed directly by humans—instead, they‘re trained on large amounts of date. During that training process, they learn their own strategies to solve problems. These strategies are encoded in the billions of computations a model performs for every word it writes. They arrive inscrutable to us, the model's developers. This means that we don't understand how models do most of the things they do.",
        "url": "https://www.anthropic.com/research/tracing-thoughts-language-model",
        "language": "en"
    },
    {
        "title": "What is DeepSeek and why is it disrupting the AI sector?",
        "source": "Reuters",
        "date": "2025-01-28",
        "summary": "Chinese startup DeepSeek's launch of its latest AI models, which it says are on a par or better than industry-leading models in the United States at a fraction of the cost, is threatening to upset the technology world order. The company has attracted attention in global AI circles after writing in a paper last month that the training of DeepSeek-V3 required less than $6 million worth of computing power from Nvidia H800 chips.",
        "url": "https://www.reuters.com/technology/artificial-intelligence/what-is-deepseek-why-is-it-disrupting-ai-sector-2025-01-27/",
        "language": "en"
    },
    {
        "title": "DeepSeek-R1 Release",
        "source": "DeepSeek",
        "date": "2025-01-20",
        "summary": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.",
        "url": "https://api-docs.deepseek.com/news/news250120",
        "language": "en"
    },
    {
        "title": "Introducing DeepSeek-V3",
        "source": "DeepSeek",
        "date": "2024-12-26",
        "summary": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.",
        "url": "https://api-docs.deepseek.com/news/news1226",
        "language": "en"
    },
    {
        "title": "Bard agora é Gemini: experimente o Ultra 1.0 e o novo aplicativo",
        "source": "Google",
        "date": "2024-02-08",
        "summary": "Desde que lançamos o Bard no ano passado, pessoas de todo o mundo têm usado a ferramenta para colaborar com a IA de uma maneira completamente nova — para se preparar para entrevistas de emprego, depurar códigos, debater novas ideias de negócios ou, como anunciamos na semana passada, criar imagens criativas. Nossa missão com o Bard sempre foi fornecer um acesso direto aos nossos modelos de IA, e Gemini representa nossa família de modelos mais potentes. Para refletir isso, Bard agora será conhecido simplesmente como Gemini.",
        "url": "https://blog.google/intl/pt-br/gemini/bard-se-torna-gemini-experimente-o-ultra-10-e-um-novo-aplicativo-movel-hoje/",
        "language": "pt"
    },
    {
        "title": "ChatGPT broke the Turing test — the race is on for new ways to assess AI",
        "source": "https://www.nature.com/articles/d41586-023-02361-7",
        "date": "2023-07-25",
        "summary": "The world's best artificial intelligence (AI) systems can pass tough exams, write convincingly human essays and chat so fluently that many find their output indistinguishable from people's. What can't they do? Solve simple visual logic puzzles. In a test consisting of a series of brightly coloured blocks arranged on a screen, most people can spot the connecting patterns. But GPT-4, the most advanced version of the AI system behind the chatbot ChatGPT and the search engine Bing, gets barely one-third of the puzzles right in one category of patterns and as little as 3% correct in another, according to a report by researchers this May1.",
        "url": "https://www.nature.com/articles/d41586-023-02361-7",
        "language": "en"
    }
]