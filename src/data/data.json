[
    {
        "title": "",
        "source": "",
        "date": "",
        "summary": "",
        "url": "",
        "language": ""
    },
    {
        "date": "2025-09-05",
        "title": "Por que os modelos de linguagem alucinam?",
        "source": "OpenAI",
        "summary": "A OpenAI tem a missão de criar sistemas de IA mais úteis e confiáveis. Por mais que os modelos de linguagem venham melhorando, ainda há um impasse que é difícil de eliminar totalmente: as alucinações. Ou seja, aqueles momentos em que um modelo gera com confiança uma resposta que não é verdadeira. Nosso novo artigo de investigação defende que os modelos de linguagem alucinam porque os treinamentos e avaliações tradicionais recompensam adivinhações e não deixam espaço para que se reconheça incertezas.",
        "url": "https://openai.com/pt-BR/index/why-language-models-hallucinate/",
        "language": "pt"
    },
    {
        "date": "2025-08-14",
        "title": "Introducing Gemma 3 270M: The compact model for hyper-efficient AI",
        "source": "Google",
        "summary": "Today, we're adding a new, highly specialized tool to the Gemma 3 toolkit: Gemma 3 270M, a compact, 270-million parameter model designed from the ground up for task-specific fine-tuning with strong instruction-following and text structuring capabilities already trained in.",
        "url": "https://developers.googleblog.com/en/introducing-gemma-3-270m/",
        "language": "en"
    },
    {
        "date": "2025-08-07",
        "title": "Chegou o GPT-5",
        "source": "OpenAI",
        "summary": "O GPT‑5 é mais inteligente em todos os parâmetros, oferecendo respostas mais úteis em matemática, ciências, finanças, direito e muito mais. É como ter uma equipe de especialistas à disposição para tudo que você quer saber.",
        "url": "https://openai.com/pt-BR/gpt-5/",
        "language": "pt"
    },
    {
        "date": "2025-07-22",
        "title": "Context Engineering: 2025’s #1 Skill in AI",
        "source": "Decoding AI",
        "summary": "Let’s get one thing straight: if you’re still only talking about 'prompt engineering,' you’re behind the curve. In the early days of Large Language Models (LLMs), crafting the perfect prompt was the name of the game. For simple chatbots in 2022, it was enough. Then came Retrieval-Augmented Generation (RAG) in 2023, where we started feeding models domain-specific knowledge. Now, we have tool-using, memory-enabled agents that need to build relationships and maintain state over time. The single-interaction focus of prompt engineering just doesn’t cut it anymore.",
        "url": "https://decodingml.substack.com/p/context-engineering-2025s-1-skill",
        "language": "en"
    },
    {
        "date": "2025-07-09",
        "title": "Grok, IA de Musk, exalta Hitler em postagens e apaga conteúdo após denúncias",
        "source": "G1",
        "summary": "O Grok, inteligência artificial criada por Elon Musk e integrada ao X, publicou nesta terça-feira (8) conteúdos antissemitas e de exaltação a Adolf Hitler. As publicações foram apagadas pela xAI, empresa responsável pela IA do Musk, após reclamações de usuários do X e da Liga Antidifamação, uma ONG judaica com sede nos EUA, informou a agência de notícias Reuters.",
        "url": "https://g1.globo.com/tecnologia/noticia/2025/07/09/grok-ia-de-musk-exalta-hitler-em-postagens-e-apaga-conteudo-apos-denuncias.ghtml",
        "language": "pt"
    },
    {
        "date": "2025-07-02",
        "title": "Context Engineering",
        "source": "LangChain",
        "summary": "As Andrej Karpathy puts it, LLMs are like a new kind of operating system. The LLM is like the CPU and its context window is like the RAM, serving as the model’s working memory. Just like RAM, the LLM context window has limited capacity to handle various sources of context. And just as an operating system curates what fits into a CPU’s RAM, we can think about “context engineering” playing a similar role.",
        "url": "https://blog.langchain.com/context-engineering-for-agents/",
        "language": "en"
    },
    {
        "date": "2025-06-20",
        "title": "Por que a Inteligência Artificial mente quando diz que “está pensando” – e por que isso importa",
        "source": "The Conversation",
        "summary": "Os avanços recentes em Inteligência Artificial (IA) criaram uma ilusão convincente. Sistemas como ChatGPT, Copilot ou Gemini nos seduzem pela aparente capacidade de pensar. Respondem a perguntas complexas, produzem textos articulados e até parecem refletir sobre suas próprias escolhas. Mas não se engane: essas máquinas não possuem raciocínio lógico, compreensão de conceitos nem consciência. Na prática, lidamos com sistemas que reconhecem padrões em nossa linguagem, sem de fato compreenderem o que dizem. E isso tem implicações importantes em como usamos, avaliamos e regulamos essas tecnologias.",
        "url": "https://theconversation.com/por-que-a-inteligencia-artificial-mente-quando-diz-que-esta-pensando-e-por-que-isso-importa-258988",
        "language": "pt"
    },
    {
        "date": "2025-06-08",
        "title": "Novos vídeos hiper-realistas feitos com inteligência artificial criam desafio de distinguir o que é real",
        "source": "G1",
        "summary": "Uma nova ferramenta de inteligência artificial do Google está mudando a forma como vídeos são criados. Chamada de Veo 3, a tecnologia permite gerar cenas realistas com personagens, trilhas sonoras e até sotaques, tudo a partir de comandos de texto.",
        "url": "https://g1.globo.com/fantastico/noticia/2025/06/08/novos-videos-hiper-realistas-feitos-com-inteligencia-artificial-criam-desafio-de-distinguir-o-que-e-real.ghtml",
        "language": "pt"
    },
    {
        "date": "2025-06-03",
        "title": "Empresa prometia IA revolucionária, mas eram 700 humanos trabalhando",
        "source": "Olhar Digital",
        "summary": "A inteligência artificial está na moda. Por conta disso, diversas startups têm investido de forma pesada na tecnologia para os mais diversos propósitos. No entanto, nem todas são, de fato, o que dizem ou parecem ser. A Builder.ai, por exemplo, prometia revolucionar a criação de aplicativos com IA. O problema é que seu sistema de redes neurais era, na verdade, composto por uma equipe de 700 engenheiros humanos. A revelação da fraude fez com que a companhia decretasse falência.",
        "url": "https://olhardigital.com.br/2025/06/03/pro/empresa-prometia-ia-revolucionaria-mas-eram-700-humanos-trabalhando/",
        "language": "pt"
    },
    {
        "date": "2025-05-29",
        "title": "Wait a minute! Researchers say AI's 'chains of thought' are not signs of human-like reasoning",
        "source": "The Decoder",
        "summary": "A research team from Arizona State University warns against interpreting intermediate steps in language models as human thought processes. The authors see this as a dangerous misconception with far-reaching consequences for research and application.",
        "url": "https://the-decoder.com/wait-a-minute-researchers-say-ais-chains-of-thought-are-not-signs-of-human-like-reasoning/",
        "language": "en"
    },
    {
        "date": "2025-05-18",
        "title": "[Literature Review] Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens",
        "source": "Moonlight",
        "summary": "This paper critically examines the common interpretation that the effectiveness of intermediate tokens, often referred to as 'Chains of Thought' (CoT) or reasoning traces, in large reasoning models stems from their semantic meaningfulness and reflection of algorithmic reasoning processes. The authors challenge the anthropomorphism of such outputs, arguing that performance improvements observed when training models to generate intermediate tokens may not be causally linked to the correctness or semantic validity of these tokens.",
        "url": "https://www.themoonlight.io/en/review/beyond-semantics-the-unreasonable-effectiveness-of-reasonless-intermediate-tokens",
        "language": "en"
    },
    {
        "date": "2025-04-05",
        "title": "The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation",
        "source": "Meta",
        "summary": "As more people continue to use artificial intelligence to enhance their daily lives, it’s important that the leading models and systems are openly available so everyone can build the future of personalized experiences. Today, we’re excited to announce the most advanced suite of models that support the entire Llama ecosystem. We’re introducing Llama 4 Scout and Llama 4 Maverick, the first open-weight natively multimodal models with unprecedented context length support and our first built using a mixture-of-experts (MoE) architecture. We’re also previewing Llama 4 Behemoth, one of the smartest LLMs in the world and our most powerful yet to serve as a teacher for our new models.",
        "url": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
        "language": "en"
    },
    {
        "date": "2025-04-03",
        "title": "Reasoning models don't always say what they think",
        "source": "Anthropic",
        "summary": "Since late last year, “reasoning models” have been everywhere. These are AI models—such as Claude 3.7 Sonnet—that show their working: as well as their eventual answer, you can read the (often fascinating and convoluted) way that they got there, in what’s called their “Chain-of-Thought”.",
        "url": "https://www.anthropic.com/research/reasoning-models-dont-say-think",
        "language": "en"
    },
    {
        "date": "2025-03-27",
        "title": "Tracing the thoughts of a large language model",
        "source": "Anthropic",
        "summary": "Language models like Claude aren't programmed directly by humans—instead, they‘re trained on large amounts of date. During that training process, they learn their own strategies to solve problems. These strategies are encoded in the billions of computations a model performs for every word it writes. They arrive inscrutable to us, the model’s developers. This means that we don’t understand how models do most of the things they do.",
        "url": "https://www.anthropic.com/research/tracing-thoughts-language-model",
        "language": "en"
    },
    {
        "title": "What is DeepSeek and why is it disrupting the AI sector?",
        "source": "Reuters",
        "date": "2025-01-28",
        "summary": "Chinese startup DeepSeek's launch of its latest AI models, which it says are on a par or better than industry-leading models in the United States at a fraction of the cost, is threatening to upset the technology world order. The company has attracted attention in global AI circles after writing in a paper last month that the training of DeepSeek-V3 required less than $6 million worth of computing power from Nvidia H800 chips.",
        "url": "https://www.reuters.com/technology/artificial-intelligence/what-is-deepseek-why-is-it-disrupting-ai-sector-2025-01-27/",
        "language": "en"
    },
    {
        "title": "DeepSeek-R1 Release",
        "source": "DeepSeek",
        "date": "2025-01-20",
        "summary": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.",
        "url": "https://api-docs.deepseek.com/news/news250120",
        "language": "en"
    },
    {
        "title": "Introducing DeepSeek-V3",
        "source": "DeepSeek",
        "date": "2024-12-26",
        "summary": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.",
        "url": "https://api-docs.deepseek.com/news/news1226",
        "language": "en"
    },
    {
        "title": "Bard agora é Gemini: experimente o Ultra 1.0 e o novo aplicativo",
        "source": "Google",
        "date": "2024-02-08",
        "summary": "Desde que lançamos o Bard no ano passado, pessoas de todo o mundo têm usado a ferramenta para colaborar com a IA de uma maneira completamente nova — para se preparar para entrevistas de emprego, depurar códigos, debater novas ideias de negócios ou, como anunciamos na semana passada, criar imagens criativas. Nossa missão com o Bard sempre foi fornecer um acesso direto aos nossos modelos de IA, e Gemini representa nossa família de modelos mais potentes. Para refletir isso, Bard agora será conhecido simplesmente como Gemini.",
        "url": "https://blog.google/intl/pt-br/gemini/bard-se-torna-gemini-experimente-o-ultra-10-e-um-novo-aplicativo-movel-hoje/",
        "language": "pt"
    }
]